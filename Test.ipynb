{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hard Drive Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore hard drive failure data and provide device failure analysis using the Kaplan-Meier model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is data provided by BackBlaze. They are an online file backup and \n",
    "# storage company. They have posted their log files of hard drives. There are 256 S.M.A.R.T statistics recorded for each drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import lifelines as sa\n",
    "import glob, os\n",
    "from collections import OrderedDict\n",
    "from lifelines.utils import concordance_index, k_fold_cross_validation\n",
    "import patsy as pt\n",
    "from datetime import datetime\n",
    "from pylab import rcParams\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run, as the files are too large.  In place to show work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Andrew\\\\Downloads\\\\hdd\\\\\")\n",
    "\n",
    "allFiles = glob.glob(\"*.csv\")\n",
    "df = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, usecols=[0, 1, 2, 3,4, 20])\n",
    "    list_.append(df)\n",
    "df = pd.concat(list_)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\Andrew\\\\Documents\")\n",
    "\n",
    "df[\"mindate\"] = df[\"date\"].groupby(df[\"serial_number\"]).transform('min')\n",
    "df[\"maxdate\"] = df[\"date\"].groupby(df[\"serial_number\"]).transform('max')\n",
    "df[\"minhours\"] = df[\"smart_9_raw\"].groupby(df[\"serial_number\"]).transform('min')\n",
    "df[\"maxhours\"] = df[\"smart_9_raw\"].groupby(df[\"serial_number\"]).transform('max')\n",
    "df[\"nrec\"] = df[\"date\"].groupby(df[\"serial_number\"]).transform('count')\n",
    "\n",
    "df = df[[\"date\", \"serial_number\",\"model\",\"capacity_bytes\",\"mindate\",\"maxdate\",\n",
    "        \"minhours\", \"maxhours\",\"nrec\",\"failure\"]]\n",
    "\n",
    "df = df.sort_values(\"failure\",ascending=False)\n",
    "df = df.drop_duplicates([\"serial_number\"],keep=\"first\")\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "#Save off file\n",
    "df.to_csv(\"HDD-log.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}